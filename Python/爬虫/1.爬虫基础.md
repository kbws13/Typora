# HTTP原理

## URI和URL

URL：统一资源定位符

URI：统一资源标识符

例如，https://githun.com/favicon.ico既是一个URL也是一个URI，即有favicon.ico这样一个图标资源，我们用刚才的链接指定了访问它的唯一方式，其中包括访问协议https、访问路径和资源名称

URL是URI的子集，除了URL，URI还包括一个子集，叫URN，即统一资源名称。URN只为资源命名而不指定如何定位资源

URL的书写格式为`scheme://[username:password@]hostname[:port][/path][;parameters][?query][#fragment]`

- scheme：协议。常用的协议有http、https、ftp等
- username、password：用户名和密码
- hostname：主机地址。可以是域名或IP地址
- port：端口。这是服务器设定的服务端口
- path：路径。指的是网络资源在服务器中的指定地址
- parameters：参数。用来访问某个资源时的附加信息
- query：查询。用来查询某类资源，如果有多个资源，则用&隔开
- fragment：片段。对资源描述的部分补充，可以理解为资源内部的书签

## HTTP和HTTPS

HTTP：超文本传输协议，作用是把超文本数据从网络传输到本地浏览器，能够保证高效而准确的传输超文本文档

HTTPS：HTTP的安全版，即在HTTP下加入SSL层，简称HTTPS

HTTPS的安全基础是SSL，因此通过该协议传输的内容都是经过SSL加密的，SSL的主要作用有以下两种：

- 建立一个信息安全通道，保证数据传输的安全性
- 确认网站的真实性。凡是使用了HTTPS协议的网站，都可以通过单击浏览器地址栏的锁头标志来查看网站认证之后的真是信息，此外还能通过CA机构颁发的安全签章来查询

## HTTP请求过程

在浏览器中输入一个URL后回车，浏览器先向网站所在的服务器发送一个请求，网站服务器接收到请求后对其进行处理和解析，然后返回对应的响应，接着传回浏览器。由于响应里包含页面的源代码等内容，所以浏览器再对其进行解析，便将网页呈现出来

## 请求

由客户端发往服务器，分为四部分内容：请求方法、请求的网址、请求头、请求体

- 请求方法

    用于标号请求客户端请求服务器的方式，常见的请求方式有两种：GET和POST

    区别：

    - GET请求中的参数包含再URL中，数据可以在URL中看到；而POST请求的URL不会包含这些信息，数据都是通过表单的形式传输的，会包含在请求体中
    - GET请求提交的数据做多只有1024字节，POST方法没有限制

    | 方法    | 描述                                                         |
    | ------- | ------------------------------------------------------------ |
    | GET     | 请求页面，并返回页面内容                                     |
    | HEAD    | 类似于GET请求，只不过返回的响应中没有具体的内容。用于获取报头 |
    | POST    | 大多用于提交表单或上传文件，数据包含在请求体中               |
    | PUT     | 用客户端传向服务器的数据取代指定文档中的内容                 |
    | DELETE  | 请求服务器删除指定页面                                       |
    | CONNECT | 把服务器当作跳板，让服务器代替客户端访问其他页面             |
    | OPTIONS | 允许客户端查看服务器的性能                                   |
    | TRACE   | 回显服务器收到的请求。主要用于测试或诊断                     |

- 请求的网址

    请求的网址，它可以唯一确定客户端想请求的资源

- 请求头

    用来说明服务器要使用的附加信息

    - Accept：请求报头域，用于指定客户端可以接收哪些类型的信息
    - Accept-Language：用于指定客户端可接受的语言类型
    - Accept-Encoding：用于指定客户端可接受的内容编码
    - Host：用于指定请求资源的主机IP和端口号，其内容为请求URL的原始服务器或网关的位置
    - CooKie：这是网站为了辨别用户，进行会话追踪而存储在用户本地的数据，其主要功能是维持当前访问会话
    - Referer：用于标识请求是从哪个页面发过来的，服务器可以拿到这一信息并做相应的处理
    - User-Agent：简称UA，是一个特殊的字符串头，可以使服务器识别客户端使用的操作系统及版本、浏览器及版本信息。做爬虫时如果加上此信息，可以伪装成浏览器，如果不加，很可能会被识别出来
    - Content-Type：用来表示具体请求中的媒体类型信息

- 请求体

    一般承载的内容是POST请求中的表单数据，对于GET请求，请求体为空

## 响应

- 响应状态码

    | 状态码 | 说明           | 详情                                                         |
    | ------ | -------------- | ------------------------------------------------------------ |
    | 100    | 继续           | 请求者应当继续提出请求。服务器已经收到请求的一部分，正在等待另一部分 |
    | 200    | 成功           | 服务器已经成功处理了请求                                     |
    | 300    | 多种选择       | 针对请求，服务器可以执行多种请求                             |
    | 400    | 错误请求       | 服务器无法解析该请求                                         |
    | 404    | 未找到         | 服务器找不到指定的网页                                       |
    | 500    | 服务器内部错误 | 服务器遇到错误，无法完成请求                                 |
    | 503    | 服务不可用     | 服务器目前无法使用                                           |

- 响应头

    - Data：用于标识响应产生的时间
    - Last-Modified：用于指定资源最后的修改时间
    - Content-Encoding：用于指定响应内容的编码
    - Server：包含服务器的信息，例如名称、版本号等
    - Content-Type：文档类型，指定返回的数据是什么类型的
    - Set-Cookie：设置Cookie。
    - Expires：用于指定响应的过期时间，可以让代理服务器或浏览器将加载的内容更新到缓存中。当再次访问相同的内容时，就可以直接从缓存中加载，达到降低服务器负载，缩短加载时间的目的

- 响应体

    响应的正文数据都存在响应体中

# Web网页基础



# 爬虫的基本原理

## 爬虫概述

爬虫就是获取网页并提取和保存信息的自动化程序

- 获取网页

    获取网页的源代码，构建一个请求并发送给服务器，然后接收响应并对其进行解析。

    python提供了许多库，可以帮助我们实现这个过程，如urllib、requests等

- 提取信息

    获取源代码之后就是分析源代码，从中提取我们想要的数据。

    首先通用且万能的方式是正则表达式，但是构建正则表达式的过程复杂且容易出错

    另外，由于网页结构具有一定的规则，所以还有一些库是根据网页结点属性、CSS选择器或XPath来提取网页信息的，如Beautiful Soup、pyquery、lxml等

- 保存数据

    提取数据之后就是进行保存。保存数据的形式有很多，可以简单存为TXT文本或JSON文本，也可以保存到数据库，如MySQL和MongoDB等，还可以保存到远程服务器上

## 能爬怎样的数据

最常规的是HTML网页，有些网页返回的是JSON字符串，这种形式的数据方便传输和解析。

## JavaScript渲染的页面

有时，我们会遇到整个网页都是JavaScript渲染出来的，HTML只有结点跟引用。对于这种情况，我们可以分析源代码在后台Ajax接口，也可以使用Selenium、Splash、Pyppeteer、Playwright这样的库来模拟JavaScript渲染

# Session和Cookie

## 静态网页和动态网页

静态网页：有HTML编写而成，加载速度快、编写简单，但不能根据URL灵活多变的显示内容

动态网页：可以动态的解析URL中参数的变化，关联数据库并动态呈现不同的页面内容，非常的灵活多变。

## 无状态HTTP

HTTP的无状态是指HTTP协议对事务的处理是没有记忆能力的，或者说服务器并不知道客户端处于什么状态，服务器不会记录登录前后状态的变化，也就是缺少状态记录。这意味着之后如果要处理前面的信息，客户端必须重传，导致需要额外传递一些重复请求，才能获取后续响应。

所以，用两种用于保持HTTP连接状态的技术出现了，分别是Seeion和Cookie。Session在服务端，也就是网站的服务器，用来保存用户的Session信息；Cookie在客户端，也可以理解为在浏览器端，有了Cookie，浏览器在下次访问相同玩网游时就会自动带上它，并发送给服务器，服务器提供识别Cookie鉴定出哪个用户在访问，然后判断此用户是否在登录状态，并得到相应的响应。

## Session

Session，中文叫会话，其本义是指有始有终的一系列动作。

在web中，Session对象用来存储特定用户Session所需的属性及配置信息。这样，当用户在应用程序的页面之间跳转时，存储在Session对象中的变量不会丢失，会在整个用户Session中一直存在下去。当用户请求来自应用程序的页面时，如果该用户还没有Session，那么web服务器将自动创建一个Session对象。当Session过期或被放弃后，服务器将终止该Session

## Cookie

指某些网站为了鉴别用户身份、进行Session跟踪而存储在用户本地终端上的数据

- Session维持

    在客户端第一次请求服务器的时候，服务器会返回一个响应头中带有Set-Cookie字段的响应给客户端，这个字段用来标记用户。客户端浏览器会把Cookie保存起来，当下一次有相同请求时，把保存的Cookie放到请求头中一起提交给服务器。Cookie中有着Session-ID相关信息，服务器通过检查Cookie即可找到对应的Session，继而通过判断Session辨认用户状态

- 属性结构

    Cookie包含如下内容

    - Name：Cookie的名称。Cookie一旦创建，名称便不可更改
    - Value：Cookie的值。值为Unicode字符，就需要为字符编码。如果值为二进制数据，则需要使用BASE64编码
    - Domain：指定可以访问该Cookie的域名
    - Path：Cookie的使用路径。如果设置为/path/，则只有/path/页面可以访问该Cookie。如果设置为/，则本域名下的所有页面都可以访问该Cookie
    - Max-Age：Cookie的失效时间，单位为秒，常和Expires一起使用，通过此属性可以计算出Cookie的有效时间。
    - Size字段：Cookie的大小
    - HTTP字段：Cookie的httponly属性。若此属性为true，则只有在HTTP Header中才会带有此Cookie的信息，而不能通过`document.cookie`来访问此Cookie
    - Secure：是否允许使用安全协议传输Cookie。安全协议有SSL和HTTPS等，使用这些协议在网络上传输数据之前会先将数据加密。其默认值为false
    
- 会话Cookie和持久Cookie

    会话Cookie就是把Cookie放在浏览器的内存里，关闭浏览器后，Cookie即失效

    持久Cookie会把Cookie保存到客户端的硬盘里，下次还可以再次使用

# 代理的基本原理

## 基本原理

代理实际上就是代理服务器，功能是代网络用户取得网络信息。

形象点说，代理是信息的中转站。当客户端正常请求一个网站的时候，是把请求发给了Web服务器，Web服务器再把响应传回客户端。

设置代理服务器，就是在客户端和服务器之间搭了一座桥，此时客户端并非直接向Web服务器发起请求，而是把请求发送给代理服务器，然后由代理服务器把请求发送给Web服务器，Web服务器返回的响应也是由代理服务器转发给客户端的。这样的客户端同样可以正常访问网页，而且这个过程中Web服务器识别出的真实IP就不再是客户端的IP了，成功实现了IP的伪装

## 作用

- 突破自身IP的访问限制，访问一些平时不能访问的站点
- 访问一些单位或团队的内部资源
- 提高访问速度
- 隐藏真实IP

## 爬虫代理

爬取过程中万一用一个IP访问过多，此时网站会让我们输入验证码登录或直接封锁IP。

使用代理隐藏IP，让服务器误以为是代理服务器在请求自己。这样在爬取过程中不断更换代理，就可以避免IP被封锁

## 代理分类

- 根据协议区分
    - FTP代理服务器：主要用于访问FTP服务器，一般有上传、下载及缓存功能，端口一般为21、2121等
    - HTTP代理服务器：主要用于访问网页，一般有内容过滤和缓存功能，端口一般为80、8080、3128等
    - SSL/TLS代理：主要用于访问加密网站，一般有SSL或TLS加密功能，端口一般为443
    - RTSP代理：主要用于Realplayer访问Real流媒体服务器，一般有缓存功能，端口一般为554
    - Telnet代理：主要用于Telnet控制，端口一般为23
    - POP3/SMTP代理：主要用于以POP3/SMTP方式收发邮件，一般有缓存功能，端口一般有110/25
    - SOCKS代理：只是单纯的传递数据包，不关心具体协议和用法，速度快很多，一般有缓存功能，端口一般为1080
- 根据匿名程度区分
    - 高度匿名代理：会 将数据包原封不动的转发，在服务端看来似乎真的是一个普通的客户端在访问
    - 普通匿名代理：会对数据做一些改动，服务器有概率发现正在访问自己的是个代理服务器，并且有一定概率区追查客户端的真实IP
    - 透明代理：不但改动了数据包，还会告诉服务器客户端的真实IP。这种代理除了能用缓存技术提高浏览速度，用内容过滤提高安全性外，无其他显著作用，最常见的例子是内网中的硬件防火墙

## 常见代理设置

- 网上免费代理
- 使用付费代理服务
- ADSL拨号
- 蜂窝代理

# 多线程和多进程的基本原理